{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "UrjQGgr5nUHC",
   "metadata": {
    "id": "UrjQGgr5nUHC"
   },
   "source": [
    "<h1> Imports and Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eGl9mcc0nOMP",
   "metadata": {
    "id": "eGl9mcc0nOMP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: higher in /Users/kcollins/opt/anaconda3/lib/python3.8/site-packages (0.2.1)\n",
      "Requirement already satisfied: torch in /Users/kcollins/opt/anaconda3/lib/python3.8/site-packages (from higher) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/kcollins/opt/anaconda3/lib/python3.8/site-packages (from torch->higher) (3.7.4.3)\n",
      "Available device: cpu\n"
     ]
    }
   ],
   "source": [
    "!pip3 install higher\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from higher import innerloop_ctx\n",
    "import warnings\n",
    "\n",
    "#The code includes extensive warnings when run so have used this to ignore them\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set random seeds for reproducibility of results \n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# set GPU or CPU depending on available hardware\n",
    "# help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Available device: {device}\")\n",
    "\n",
    "if device == \"cuda:0\": \n",
    "  # set default so all tensors are on GPU, if available\n",
    "  # help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "\n",
    "domain_type = \"multidim_sine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T3KVOwFXFOY0",
   "metadata": {
    "id": "T3KVOwFXFOY0"
   },
   "source": [
    "<h1> Data Loading and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nMUUm70ufKHH",
   "metadata": {
    "id": "nMUUm70ufKHH"
   },
   "source": [
    "This Sine function generator is based on the repostory: https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3X51uGHDvSV",
   "metadata": {
    "id": "a3X51uGHDvSV"
   },
   "outputs": [],
   "source": [
    "class SineWaveTask_multi:\n",
    "    def __init__(self,dimensions=20):\n",
    "        self.dimensions = dimensions\n",
    "        self.a = []\n",
    "        self.b = []\n",
    "        for dim in range(self.dimensions):\n",
    "          self.a.append(np.random.uniform(0.1, 5.0))\n",
    "          self.b.append(np.random.uniform(0, 2*np.pi))\n",
    "        self.train_x = None\n",
    "        \n",
    "    def f(self, x,a,b):\n",
    "        return a * np.sin(x + b)\n",
    "        \n",
    "    def training_set(self, size=10, force_new=False):\n",
    "        if self.train_x is None and not force_new:\n",
    "            self.train_x = np.random.uniform(-5, 5, size)\n",
    "            x = self.train_x\n",
    "\n",
    "        elif not force_new:\n",
    "            x = self.train_x\n",
    "        else:\n",
    "            x = np.random.uniform(-5, 5, size)\n",
    "\n",
    "        y = self.f(x,self.a[0],self.b[0])[:,None]\n",
    "\n",
    "        for dim in range(self.dimensions-1):\n",
    "          y = np.concatenate((y,self.f(x,self.a[dim+1],self.b[dim+1])[:,None]),axis=-1)\n",
    "\n",
    "        return torch.Tensor(x[:,None]), torch.Tensor(y)\n",
    "    \n",
    "    def test_set(self, size=50):\n",
    "        x = np.linspace(-5, 5, size)\n",
    "        y = self.f(x,self.a[0],self.b[0])[:,None]\n",
    "\n",
    "        for dim in range(self.dimensions-1):\n",
    "          y = np.concatenate((y,self.f(x,self.a[dim+1],self.b[dim+1])[:,None]),axis=-1)\n",
    "\n",
    "        return torch.Tensor(x[:,None]), torch.Tensor(y)\n",
    "    \n",
    "\n",
    "TRAIN_SIZE = 20000\n",
    "TEST_SIZE = 1000\n",
    "SINE_TRAIN = [SineWaveTask_multi() for _ in range(TRAIN_SIZE)]\n",
    "SINE_TEST = [SineWaveTask_multi() for _ in range(TEST_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Ahv9M3tAJrG7",
   "metadata": {
    "id": "Ahv9M3tAJrG7"
   },
   "outputs": [],
   "source": [
    "x, y_true = SINE_TRAIN[0].training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jInHQnwIKKxH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jInHQnwIKKxH",
    "outputId": "8760f64a-0585-432f-fa26-e9189ee9a6dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cu4urLF7Q88A",
   "metadata": {
    "id": "cu4urLF7Q88A"
   },
   "source": [
    "<h1> Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "R1B0YTz6ytyN",
   "metadata": {
    "id": "R1B0YTz6ytyN"
   },
   "outputs": [],
   "source": [
    "# Define network\n",
    "class Neural_Network_multi(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=40, output_size=20):\n",
    "        super(Neural_Network_multi, self).__init__()\n",
    "        # network layers\n",
    "        self.hidden1 = nn.Linear(input_size,hidden_size)\n",
    "        self.hidden2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "        #Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        y = x\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G-ExWACxQ3mt",
   "metadata": {
    "id": "G-ExWACxQ3mt"
   },
   "source": [
    "<h1> Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1zyNHFXdOnug",
   "metadata": {
    "id": "1zyNHFXdOnug"
   },
   "outputs": [],
   "source": [
    "# The Minimum Square Error is used to evaluate the difference between prediction and ground truth\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def copy_existing_model(model):\n",
    "    # Function to copy an existing model\n",
    "    # We initialize a new model\n",
    "    new_model = Neural_Network_multi()\n",
    "    # Copy the previous model's parameters into the new model\n",
    "    new_model.load_state_dict(model.state_dict())\n",
    "    return new_model\n",
    "\n",
    "def get_samples_in_good_format(wave, num_samples=10, force_new=False):\n",
    "  #This function is used to sample data from a wave\n",
    "  x, y_true = wave.training_set(size=num_samples, force_new=force_new)\n",
    "  # We add [:,None] to get the right dimensions to pass to the model: we want K x 1 (we have scalars inputs hence the x 1)\n",
    "  # Note that we convert everything torch tensors\n",
    "  x = torch.tensor(x)\n",
    "  y_true = torch.tensor(y_true)\n",
    "  return x.to(device),y_true.to(device)\n",
    "\n",
    "def initialization_to_store_meta_losses():\n",
    "  # This function creates lists to store the meta losses\n",
    "  global store_train_loss_meta; store_train_loss_meta = []\n",
    "  global store_test_loss_meta; store_test_loss_meta = []\n",
    "\n",
    "def test_set_validation(model,new_model,wave,lr_inner,k,store_test_loss_meta):\n",
    "    # This functions does not actually affect the main algorithm, it is just used to evaluate the new model\n",
    "    new_model = training(model, wave, lr_inner, k)\n",
    "    # Obtain the loss\n",
    "    loss = evaluation(new_model, wave)\n",
    "    # Store loss\n",
    "    store_test_loss_meta.append(loss)\n",
    "\n",
    "def train_set_evaluation(new_model,wave,store_train_loss_meta):\n",
    "    loss = evaluation(new_model, wave)\n",
    "    store_train_loss_meta.append(loss) \n",
    "\n",
    "def print_losses(epoch,store_train_loss_meta,store_test_loss_meta,printing_step=1000):\n",
    "  if epoch % printing_step == 0:\n",
    "    print(f'Epochh : {epoch}, Average Train Meta Loss : {np.mean(store_train_loss_meta)}, Average Test Meta Loss : {np.mean(store_test_loss_meta)}')\n",
    "\n",
    "#This is based on the paper update rule, we calculate the difference between parameters and then this is used by the optimizer, rather than doing the update by hand\n",
    "def reptile_parameter_update(model,new_model):\n",
    "  # Zip models for the loop\n",
    "  zip_models = zip(model.parameters(), new_model.parameters())\n",
    "  for parameter, new_parameter in zip_models:\n",
    "    if parameter.grad is None:\n",
    "      parameter.grad = torch.tensor(torch.zeros_like(parameter))\n",
    "    # Here we are adding the gradient that will later be used by the optimizer\n",
    "    parameter.grad.data.add_(parameter.data - new_parameter.data)\n",
    "\n",
    "# Define commands in order needed for the metaupdate\n",
    "# Note that if we change the order it doesn't behave the same\n",
    "def metaoptimizer_update(metaoptimizer):\n",
    "  # Take step\n",
    "  metaoptimizer.step()\n",
    "  # Reset gradients\n",
    "  metaoptimizer.zero_grad()\n",
    "\n",
    "def metaupdate(model,new_model,metaoptimizer):\n",
    "  # Combine the two previous functions into a single metaupdate function\n",
    "  # First we calculate the gradients\n",
    "  reptile_parameter_update(model,new_model)\n",
    "  # Use those gradients in the optimizer\n",
    "  metaoptimizer_update(metaoptimizer)\n",
    "\n",
    "def evaluation(new_model, wave, num_samples=10, force_new=False, item = False):\n",
    "    # Get data\n",
    "    x, label = get_samples_in_good_format(wave,num_samples=num_samples, force_new=force_new)\n",
    "    # Make model prediction\n",
    "    prediction = new_model(x)\n",
    "    # Get loss\n",
    "    if item == True: #Depending on whether we need to return the loss value for storing or for backprop\n",
    "      loss = criterion(prediction,label).item()\n",
    "    else:\n",
    "      loss = criterion(prediction,label)\n",
    "    return loss\n",
    "\n",
    "def training(model, wave, lr_k, k):\n",
    "    # Create new model which we will train on\n",
    "    new_model = copy_existing_model(model)\n",
    "    # Define new optimizer\n",
    "    koptimizer = torch.optim.SGD(new_model.parameters(), lr=lr_k)\n",
    "    # Update the model multiple times, note that k>1 (do not confuse k with K)\n",
    "    for i in range(k):\n",
    "        # Reset optimizer\n",
    "        koptimizer.zero_grad()\n",
    "        # Evaluate the model\n",
    "        loss = evaluation(new_model, wave, item = False)\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        koptimizer.step()\n",
    "    return new_model\n",
    "\n",
    "# for MAML -- see MAML cell for additional citations around structure inspiration\n",
    "def task_specific_train_and_eval(model, T_i, inner_loop_optimizer, N=1):\n",
    "    #Description of the loop formulation from https://higher.readthedocs.io/en/latest/toplevel.html\n",
    "    with innerloop_ctx(model, inner_loop_optimizer, copy_initial_weights = False) as (fmodel,diffopt):\n",
    "        #get our input data and our label\n",
    "        x, label = get_samples_in_good_format(T_i,num_samples=num_samples, force_new= True)\n",
    "        per_step_loss = []\n",
    "        for _ in range(N):\n",
    "            #Get the task specific loss for our model\n",
    "            task_specifc_loss = criterion(fmodel(x), label)\n",
    "\n",
    "            #Step through the inner gradient\n",
    "            diffopt.step(task_specifc_loss)\n",
    "            \n",
    "            per_step_loss.append(task_specifc_loss.item())\n",
    "            \n",
    "        held_out_task_specific_loss = evaluation(fmodel, T_i, num_samples=num_samples, force_new=True)\n",
    "        \n",
    "        return held_out_task_specific_loss, per_step_loss, fmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-4Ps8P2IRCmF",
   "metadata": {
    "id": "-4Ps8P2IRCmF"
   },
   "source": [
    "<h1> Reptile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ogpg_DHizlC",
   "metadata": {
    "id": "8ogpg_DHizlC"
   },
   "outputs": [],
   "source": [
    "#Define important variables\n",
    "epochs = int(1e5) # number of epochs \n",
    "lr_meta=0.001 # Learning rate for meta model (outer loop)\n",
    "printing_step=1000 # how many epochs should we wait to print the loss\n",
    "lr_k=0.01 # Internal learning rate\n",
    "k=5 # Number of internal updates for each task\n",
    "\n",
    "# Initializations\n",
    "initialization_to_store_meta_losses()\n",
    "model = Neural_Network_multi()\n",
    "metaoptimizer = torch.optim.Adam(model.parameters(), lr=lr_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "-4-zQWWKFt3s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-4-zQWWKFt3s",
    "outputId": "747b2ee4-fc6a-487e-98a4-a35d0cf2f7b2"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3cd69cebc74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Print losses every 'printing_step' epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_train_loss_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_test_loss_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprinting_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-c8dc7f24f519>\u001b[0m in \u001b[0;36mprint_losses\u001b[0;34m(epoch, store_train_loss_meta, store_test_loss_meta, printing_step)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_train_loss_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_test_loss_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprinting_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprinting_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epochh : {epoch}, Average Train Meta Loss : {np.mean(store_train_loss_meta)}, Average Test Meta Loss : {np.mean(store_test_loss_meta)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#This is based on the paper update rule, we calculate the difference between parameters and then this is used by the optimizer, rather than doing the update by hand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3472\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3474\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3475\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    # Sample a sine wave (Task from training data)\n",
    "    wave = random.sample(SINE_TRAIN, 1)\n",
    "\n",
    "    # Update model predefined number of times based on k\n",
    "    new_model = training(model, wave[0], lr_k, k)\n",
    "\n",
    "    # Evalaute the loss for the training data\n",
    "    train_set_evaluation(new_model,wave[0],store_train_loss_meta)     \n",
    "    \n",
    "    #Meta-update --> Get gradient for meta loop and update\n",
    "    metaupdate(model,new_model,metaoptimizer)\n",
    "    \n",
    "    # Evalaute the loss for the test data\n",
    "    # Note that we need to sample the wave from the test data\n",
    "    wave = random.sample(SINE_TEST, 1)\n",
    "    test_set_validation(model,new_model,wave[0],lr_k,k,store_test_loss_meta)\n",
    "\n",
    "    # Print losses every 'printing_step' epochs\n",
    "    print_losses(epoch,store_train_loss_meta,store_test_loss_meta,printing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQjoz6FYctJM",
   "metadata": {
    "id": "bQjoz6FYctJM"
   },
   "source": [
    "<h1> Few Shot learning with new meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m-SPUG5Bfpe9",
   "metadata": {
    "id": "m-SPUG5Bfpe9"
   },
   "source": [
    "The model performs good few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GY84TNs8JXVH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "GY84TNs8JXVH",
    "outputId": "1f8f1545-9c7f-4c55-bd7a-520642859f4d"
   },
   "outputs": [],
   "source": [
    "wave = SineWaveTask_multi(); \n",
    "k_shot_updates = 4\n",
    "initialization_to_store_meta_losses()\n",
    "for shots in range(k_shot_updates):\n",
    "    new_model = training(model, wave, lr_k, shots)\n",
    "    train_set_evaluation(new_model,wave,store_train_loss_meta) \n",
    "\n",
    "plt.plot(store_train_loss_meta,label = 'Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('k shots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f7a50",
   "metadata": {
    "id": "5lL1NN2OPBSD"
   },
   "source": [
    "## Second-Order MAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19ec9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter =  0  Current Loss 4.402935028076172  Val Loss:  4.536915302276611\n",
      "Iter =  5000  Current Loss 3.526278177992484  Val Loss:  3.5197749872299178\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Handling computation graphs and second-order backprop help and partial inspiration from: \n",
    "- https://discuss.pytorch.org/t/how-to-save-computation-graph-of-a-gradient/128286/2 \n",
    "- https://discuss.pytorch.org/t/when-do-i-use-create-graph-in-autograd-grad/32853/3 \n",
    "- https://lucainiaoge.github.io/download/PyTorch-create_graph-is-true_Tutorial_and_Example.pdf\n",
    "- https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "- https://discuss.pytorch.org/t/how-to-manually-update-network-parameters-while-keeping-track-of-its-computational-graph/131642/2\n",
    "- https://discuss.pytorch.org/t/how-to-calculate-2nd-derivative-of-a-likelihood-function/15085/3\n",
    "- https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html\n",
    "- https://higher.readthedocs.io/en/latest/toplevel.html\n",
    "\n",
    "Neural network configuration and helper class functions copied directly from \n",
    "-https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb\n",
    "\n",
    "Note, different ways to refer to the task-specific vs. meta/aggregate updates to the parameters\n",
    "Sometimes called \"inner\" and \"outer\" loop, respectively\n",
    "Here, refered to as \"task_specific\" and \"agg\"/meta\" (the latter, for consistency w/ ocariz code)\n",
    "'''\n",
    "\n",
    "\n",
    "#Instantiate the model network\n",
    "model = Neural_Network_multi()\n",
    "# move to the current device (GPU or CPU)\n",
    "# help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "model.to(device)\n",
    "\n",
    "T = 25 # num tasks\n",
    "N = 1 # number of inner loop steps (notation from: https://www.bayeswatch.com/2018/11/30/HTYM/)\n",
    "num_samples = 10 # number of samples to draw from the task\n",
    "lr_task_specific = 0.01 # task specific learning rate\n",
    "lr_meta = 0.001 # meta-update learning rate\n",
    "num_epochs = 10000#70001 #Number of iterations for outer loop\n",
    "printing_step = 5000 # show log of loss every x epochs\n",
    "\n",
    "#Used to store the validation losses\n",
    "metaLosses = []\n",
    "metaValLosses = []\n",
    "\n",
    "#Meta-optimizer for the outer loop\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr = lr_meta)\n",
    "cosScheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=meta_optimizer, T_max=num_epochs,\n",
    "                   eta_min=0, verbose = False)\n",
    "\n",
    "#Inner optimizer, we were doing this by hand previously\n",
    "inner_loop_optimizer = torch.optim.SGD(model.parameters(), lr = lr_task_specific)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    cosScheduler.step(epoch=epoch)\n",
    "    # store loss over all tasks to then do a large meta-level update of initial params\n",
    "    # idea/help from video: https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "    meta_loss = None\n",
    "    \n",
    "    #Sample a new wave each time\n",
    "    waves = [SineWaveTask_multi() for _ in range(T)]\n",
    "    \n",
    "    #Loop through all of the tasks\n",
    "    for i, T_i in enumerate(waves): \n",
    "        held_out_task_specific_loss, _, _ = task_specific_train_and_eval(model, T_i, inner_loop_optimizer, N)\n",
    "        if meta_loss is None: \n",
    "            meta_loss = held_out_task_specific_loss\n",
    "        else:\n",
    "            meta_loss += held_out_task_specific_loss\n",
    "            \n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss /= T\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    metaLosses.append(meta_loss.item())\n",
    "    \n",
    "    # validation \n",
    "    val_wave = SineWaveTask_multi() # our own addition -- can vary\n",
    "    val_loss, _, _ = task_specific_train_and_eval(model, val_wave, inner_loop_optimizer, N)\n",
    "    metaValLosses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % printing_step == 0:\n",
    "        print(\"Iter = \", epoch, \" Current Loss\", np.mean(metaLosses), \" Val Loss: \", np.mean(metaValLosses))\n",
    "        # saving model help from: \n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), f\"{domain_type}_maml_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07479119",
   "metadata": {},
   "source": [
    "<h1> Few Shot learning with new meta-model (MAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effd0720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run k-shot to check how rapidly we are able to adapt to unseen tasks\n",
    "# starting w/ a single unseen task\n",
    "\n",
    "test_wave = SineWaveTask_multi()\n",
    "num_k_shots = 10\n",
    "\n",
    "# use model returned from earlier optimization\n",
    "inner_loop_optimizer = torch.optim.SGD(model.parameters(), lr = lr_task_specific)\n",
    "held_out_task_specific_loss, metaTrainLosses, _ = task_specific_train_and_eval(model, test_wave, inner_loop_optimizer, num_k_shots)\n",
    "\n",
    "plt.plot(metaTrainLosses)\n",
    "plt.xlim([0,num_k_shots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7bf11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_losses = []\n",
    "num_eval = 100 \n",
    "num_k_shots = 10\n",
    "\n",
    "for test_eval in range(num_eval): \n",
    "    test_wave = SineWaveTask_multi()\n",
    "\n",
    "    # use model returned from earlier optimization\n",
    "    inner_loop_optimizer = torch.optim.SGD(model.parameters(), lr = lr_task_specific)\n",
    "    held_out_task_specific_loss, metaTrainLosses, _ = task_specific_train_and_eval(model, test_wave, inner_loop_optimizer, num_k_shots)\n",
    "\n",
    "    all_losses.append(np.array(metaTrainLosses))\n",
    "\n",
    "all_losses = np.array(all_losses)\n",
    "np.save(f\"maml_ca_multi_sine_{num_k_shots}.npy\", all_losses)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "mean_loss = np.mean(all_losses, axis=0)\n",
    "\n",
    "# confidence interval plotting help from: https://stackoverflow.com/questions/59747313/how-to-plot-confidence-interval-in-python\n",
    "y = mean_loss\n",
    "x = list(range(num_k_shots))\n",
    "ci = 1.96 * np.std(all_losses, axis=0)**2/np.sqrt(len(y))\n",
    "\n",
    "ax_size=16\n",
    "title_size=18\n",
    "                                                  \n",
    "ax.plot(x, y, linewidth=3, label=f\"Mean Loss\")\n",
    "ax.fill_between(x, (y-ci), (y+ci), alpha=.5,label=f\"95% CI\")\n",
    "ax.set_xlabel(\"Gradient Steps\",fontsize=ax_size)\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\",fontsize=ax_size)\n",
    "ax.set_title(\"Sine Wave Regression: k-Shot Evaluation\",fontsize=title_size)\n",
    "ax.legend()#loc=\"upper right\")\n",
    "plt.savefig(\"sine_ca_wave_multidim_reg_kshot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef57abb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Error: 4.2695644819736485, Var: 0.490118706521123\n",
      "Step: 1, Error: 2.3154575663805006, Var: 0.34405399236514983\n",
      "Step: 9, Error: 1.6360280320048333, Var: 0.24757275091139272\n"
     ]
    }
   ],
   "source": [
    "analysis_steps = [0, 1, num_k_shots-1]\n",
    "for analysis_step in analysis_steps: \n",
    "    print(f\"Step: {analysis_step}, Error: {mean_loss[analysis_step]}, Var: {ci[analysis_step]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a737d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second-Order MAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92052e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Handling computation graphs and second-order backprop help and partial inspiration from: \n",
    "- https://discuss.pytorch.org/t/how-to-save-computation-graph-of-a-gradient/128286/2 \n",
    "- https://discuss.pytorch.org/t/when-do-i-use-create-graph-in-autograd-grad/32853/3 \n",
    "- https://lucainiaoge.github.io/download/PyTorch-create_graph-is-true_Tutorial_and_Example.pdf\n",
    "- https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "- https://discuss.pytorch.org/t/how-to-manually-update-network-parameters-while-keeping-track-of-its-computational-graph/131642/2\n",
    "- https://discuss.pytorch.org/t/how-to-calculate-2nd-derivative-of-a-likelihood-function/15085/3\n",
    "- https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html\n",
    "- https://higher.readthedocs.io/en/latest/toplevel.html\n",
    "\n",
    "Neural network configuration and helper class functions copied directly from \n",
    "-https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb\n",
    "\n",
    "Note, different ways to refer to the task-specific vs. meta/aggregate updates to the parameters\n",
    "Sometimes called \"inner\" and \"outer\" loop, respectively\n",
    "Here, refered to as \"task_specific\" and \"agg\"/meta\" (the latter, for consistency w/ ocariz code)\n",
    "'''\n",
    "\n",
    "\n",
    "#Instantiate the model network\n",
    "model = Neural_Network_multi()\n",
    "# move to the current device (GPU or CPU)\n",
    "# help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "model.to(device)\n",
    "\n",
    "T = 25 # num tasks\n",
    "N = 1 # number of inner loop steps (notation from: https://www.bayeswatch.com/2018/11/30/HTYM/)\n",
    "num_samples = 10 # number of samples to draw from the task\n",
    "lr_task_specific = 0.01 # task specific learning rate\n",
    "lr_meta = 0.001 # meta-update learning rate\n",
    "num_epochs = 10000#70001 #Number of iterations for outer loop\n",
    "printing_step = 5000 # show log of loss every x epochs\n",
    "\n",
    "#Used to store the validation losses\n",
    "metaLosses = []\n",
    "metaValLosses = []\n",
    "\n",
    "#Meta-optimizer for the outer loop\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr = lr_meta)\n",
    "\n",
    "#Inner optimizer, we were doing this by hand previously\n",
    "inner_loop_optimizer = torch.optim.SGD(model.parameters(), lr = lr_task_specific)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # store loss over all tasks to then do a large meta-level update of initial params\n",
    "    # idea/help from video: https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "    meta_loss = None\n",
    "    \n",
    "    #Sample a new wave each time\n",
    "    waves = [SineWaveTask_multi() for _ in range(T)]\n",
    "    \n",
    "    #Loop through all of the tasks\n",
    "    for i, T_i in enumerate(waves): \n",
    "        held_out_task_specific_loss, _, _ = task_specific_train_and_eval(model, T_i, inner_loop_optimizer, N)\n",
    "        if meta_loss is None: \n",
    "            meta_loss = held_out_task_specific_loss\n",
    "        else:\n",
    "            meta_loss += held_out_task_specific_loss\n",
    "            \n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss /= T\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    metaLosses.append(meta_loss.item())\n",
    "    \n",
    "    # validation \n",
    "    val_wave = SineWaveTask_multi() # our own addition -- can vary\n",
    "    val_loss, _, _ = task_specific_train_and_eval(model, val_wave, inner_loop_optimizer, N)\n",
    "    metaValLosses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % printing_step == 0:\n",
    "        print(\"Iter = \", epoch, \" Current Loss\", np.mean(metaLosses), \" Val Loss: \", np.mean(metaValLosses))\n",
    "        # saving model help from: \n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), f\"{domain_type}_maml_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Reptile_multidimensional_sinewave.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
