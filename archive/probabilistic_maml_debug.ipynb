{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308b967c-1101-4ba5-aa0e-501aec71f4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu\n",
      "Available device: cpu\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MAML with uncertainty\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns \n",
    "from math import pi as PI\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "from higher import innerloop_ctx\n",
    "import warnings\n",
    "import importlib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set random seeds for reproducibility of results \n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# set GPU or CPU depending on available hardware\n",
    "# help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Available device: {device}\")\n",
    "\n",
    "if device == \"cuda:0\": \n",
    "  # set default so all tensors are on GPU, if available\n",
    "  # help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# import backbone model, dataset, and code utils\n",
    "from models import Neural_Network, Prob_Neural_Network\n",
    "from constants import *\n",
    "from utils import *\n",
    "import analysis_utils\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f622897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dataset\n",
    "'''\n",
    "# specify the number of tasks to sample per meta-set\n",
    "# note: we end up sampling tasks at random, so sizes are not particularly relevant\n",
    "# artifact of the way we structured the dataset earlier \n",
    "meta_train_size=10000\n",
    "meta_val_size=1000\n",
    "meta_test_size=1000\n",
    "meta_train_eval_size = 20\n",
    "\n",
    "dataset = RegressionDomain(amp_min=amp_min, amp_max=amp_max, \n",
    "                           phase_min=phase_min, phase_max=phase_max, \n",
    "                           train_size=meta_train_size, val_size=meta_val_size, test_size=meta_test_size)\n",
    "\n",
    "meta_val_set = dataset.get_meta_val_batch()\n",
    "meta_test_set = dataset.get_meta_test_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee8d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create custom probabilistic loss\n",
    "Help from: \n",
    "- https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
    "- https://pytorch.org/docs/stable/distributions.html#normal\n",
    "- https://towardsdatascience.com/predicting-probability-distributions-using-neural-networks-abef7db10eac\n",
    "'''\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "def log_prob_loss(output, target): \n",
    "    # follows format for custom loss functions in pytorch from: https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
    "    # here, we assume output are the mean and sigma per x\n",
    "    mu, sigma = output\n",
    "    sigma += 1e-15 # avoid 0.0 issues\n",
    "    predicted_gaussians = Normal(mu, sigma)\n",
    "    return -predicted_gaussians.log_prob(target)\n",
    "\n",
    "criterion = log_prob_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0b0448-3fb2-4b40-b649-9939da4f78ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e516fc5eef69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#Loop through all of the tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtrain_eval_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_specific_train_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_loop_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mheld_out_task_specific_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmeta_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlmi4_MAML_reproduce/utils.py\u001b[0m in \u001b[0;36mtask_specific_train_and_eval\u001b[0;34m(model, T_i, inner_loop_optimizer, criterion, K, N, extract_task_info, with_noise, noise_dev)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m#Step through the inner gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mdiffopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_specifc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mper_step_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_specifc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/higher/optim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, loss, params, override, grad_callback, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         ]\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         all_grads = _torch.autograd.grad(\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mgrad_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Handling computation graphs and second-order backprop help and partial inspiration from: \n",
    "- https://discuss.pytorch.org/t/how-to-save-computation-graph-of-a-gradient/128286/2 \n",
    "- https://discuss.pytorch.org/t/when-do-i-use-create-graph-in-autograd-grad/32853/3 \n",
    "- https://lucainiaoge.github.io/download/PyTorch-create_graph-is-true_Tutorial_and_Example.pdf\n",
    "- https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "- https://discuss.pytorch.org/t/how-to-manually-update-network-parameters-while-keeping-track-of-its-computational-graph/131642/2\n",
    "- https://discuss.pytorch.org/t/how-to-calculate-2nd-derivative-of-a-likelihood-function/15085/3\n",
    "- https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html\n",
    "- https://higher.readthedocs.io/en/latest/toplevel.html\n",
    "\n",
    "Neural network configuration and helper class functions copied directly from \n",
    "-https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb\n",
    "\n",
    "Note, different ways to refer to the task-specific vs. meta/aggregate updates to the parameters\n",
    "Sometimes called \"inner\" and \"outer\" loop, respectively\n",
    "Here, refered to as \"task_specific\" and \"agg\"/meta\" (the latter, for consistency w/ ocariz code)\n",
    "'''\n",
    "\n",
    "\n",
    "#Instantiate the model network\n",
    "model = Prob_Neural_Network()\n",
    "# move to the current device (GPU or CPU)\n",
    "# help from: https://stackoverflow.com/questions/46704352/porting-pytorch-code-from-cpu-to-gpu\n",
    "model.to(device)\n",
    "\n",
    "N = 1 # number of inner loop steps (notation from: https://www.bayeswatch.com/2018/11/30/HTYM/)\n",
    "K = 10 # number of samples to draw from the task\n",
    "\n",
    "#Used to store the validation losses\n",
    "metaLosses = []\n",
    "metaValLosses = []\n",
    "\n",
    "#Meta-optimizer for the outer loop\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr = lr_meta)\n",
    "\n",
    "#Inner optimizer, we were doing this by hand previously\n",
    "inner_loop_optimizer = torch.optim.SGD(model.parameters(), lr = lr_task_specific)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # store loss over all tasks to then do a large meta-level update of initial params\n",
    "    # idea/help from video: https://www.youtube.com/watch?v=IkDw22a8BDE\n",
    "    meta_loss = None\n",
    "    \n",
    "    waves = dataset.get_meta_train_batch(task_batch_size=T)\n",
    "    \n",
    "    #Loop through all of the tasks\n",
    "    for i, T_i in enumerate(waves): \n",
    "        train_eval_info = task_specific_train_and_eval(model, T_i, inner_loop_optimizer, criterion, K=K, N=N)\n",
    "        held_out_task_specific_loss = train_eval_info[0]\n",
    "        if meta_loss is None: \n",
    "            meta_loss = held_out_task_specific_loss\n",
    "        else:\n",
    "            meta_loss += held_out_task_specific_loss\n",
    "            \n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss /= T\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    metaLosses.append(meta_loss.item())\n",
    "    \n",
    "    # validation \n",
    "    val_wave = dataset.get_meta_val_batch(task_batch_size=1)[0]\n",
    "    val_train_eval_info = task_specific_train_and_eval(model, val_wave, inner_loop_optimizer, criterion, K=K, N=N)\n",
    "    val_loss = val_train_eval_info[0]\n",
    "    metaValLosses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % printing_step == 0:\n",
    "        print(\"Iter = \", epoch, \" Current Loss\", np.mean(metaLosses), \" Val Loss: \", np.mean(metaValLosses))\n",
    "        # saving model help from: \n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), \"sample_maml_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e3942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5410])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# help from torch distributions documentation: https://pytorch.org/docs/stable/distributions.html#normal\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a458f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = dataset.get_meta_train_batch(task_batch_size=T)[0]\n",
    "samples = wave.get_samples()\n",
    "x = samples[\"input\"]\n",
    "y_true = samples[\"output\"]\n",
    "x = torch.tensor(x[:,None])\n",
    "y_true = torch.tensor(y_true[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb3b90c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1909],\n",
       "        [ 4.1874],\n",
       "        [ 1.8886],\n",
       "        [ 3.8937],\n",
       "        [ 2.8011],\n",
       "        [-3.1322],\n",
       "        [-0.9134],\n",
       "        [-4.8684],\n",
       "        [ 1.8384],\n",
       "        [ 4.4018]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = get_samples_in_good_format(wave)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec0bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4239e-01],\n",
       "        [ 3.9643e+35],\n",
       "        [ 3.1114e+35],\n",
       "        [ 5.8735e+35],\n",
       "        [ 9.0731e+35],\n",
       "        [ 1.8262e+00],\n",
       "        [ 9.5487e+00],\n",
       "        [ 7.0673e-02],\n",
       "        [ 2.7476e+35],\n",
       "        [ 2.7229e+35]], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Prob_Neural_Network()\n",
    "mu, sigma = model(x)\n",
    "sigma += 1e-18 # avoid exact zero\n",
    "m = Normal(mu, sigma)\n",
    "-m.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d2e7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68cd01dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2675])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.log_prob(wave.get_samples()['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804e161-9383-419e-8948-11fd829167fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(analysis_utils)\n",
    "\n",
    "num_k_shots = 10\n",
    "K = 10\n",
    "num_eval=100\n",
    "file_tag = \"baseline_maml\"\n",
    "res = analysis_utils.k_shot_evaluation(model, dataset, num_k_shots=num_k_shots, K=K, num_eval=num_eval,\n",
    "                        file_tag=file_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81614284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
