{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9617753",
   "metadata": {
    "id": "f9617753"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to explore the data generation and loading utils for MAML reproduction\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns \n",
    "from math import pi as PI\n",
    "import random\n",
    "\n",
    "ax_size = 14\n",
    "title_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6a6e00",
   "metadata": {
    "id": "5d6a6e00"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a master data class to ensure analogous structure across tasks\n",
    "Help on writing abstract classes from: \n",
    "https://www.geeksforgeeks.org/abstract-classes-in-python/\n",
    "\n",
    "Meta-train has training and test sets\n",
    "Also have meta-val and meta-test sets (at the task level)\n",
    "Help for understanding training and test set structure from [see especially for classification]: \n",
    "https://meta-learning.fastforwardlabs.com/\n",
    "\n",
    "\n",
    "What do we want out of our data generation code? \n",
    "- specify a particular task instance\n",
    "(e.g., amplitude and phase; N number of discrete classes)\n",
    "- extract batches of tasks for train, val, and test\n",
    "- extract sample from a given task of size K for training (and other for testing)\n",
    "'''\n",
    "\n",
    "class Domain(): \n",
    "    \n",
    "    def get_meta_train_batch(self, task_batch_size):\n",
    "        # yields the set of meta-training tasks, each of which has train and test sets\n",
    "        pass \n",
    "    \n",
    "    def get_meta_val_batch(self, task_batch_size):\n",
    "        # yields meta-val tasks (each just has a single data set)\n",
    "        pass\n",
    "\n",
    "    def get_meta_test_batch(self, task_batch_size):\n",
    "        # yields meta-test tasks (each just has a single data set)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dfcbd5",
   "metadata": {
    "id": "89dfcbd5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Regression task, as per MAML Section 5.1 (https://arxiv.org/pdf/1703.03400.pdf)\n",
    "Specifically, sine wave generation \n",
    "\n",
    "Code inspired by and modified from: \n",
    "https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb\n",
    "\n",
    "Checked original MAML code to ensure resampling for all stages of sinusoid:\n",
    "https://github.com/cbfinn/maml/blob/master/data_generator.py\n",
    "'''\n",
    "\n",
    "class RegressionDomain(Domain): \n",
    "    \n",
    "    '''\n",
    "    Each task is a sine wave\n",
    "    Parameterized by amplitude and phase \n",
    "    Always drawn from w/in a specified range of x vals\n",
    "    [Values from Section 5.1 -- but we could vary??]\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, amp_min=0.1, amp_max=0.5, \n",
    "                 phase_min=0, phase_max=PI,\n",
    "                train_size=1000, val_size=100, test_size=1000): \n",
    "        \n",
    "        self.amp_min = amp_min\n",
    "        self.amp_max = amp_max\n",
    "        self.phase_min = phase_min\n",
    "        self.phase_max = phase_max\n",
    "        \n",
    "        # create initial train, val, and test \n",
    "        # parameters specify the number of unique functions we want\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        # looping to instantiate tasks idea from: https://github.com/AdrienLE/ANIML/blob/master/ANIML.ipynb\n",
    "        # help on generating random numbers in range from: https://pynative.com/python-get-random-float-numbers/\n",
    "        self.tasks = {}\n",
    "        # note: code would be more structured b/w task type for classification\n",
    "        for task_type, num_tasks in zip([\"train\", \"val\", \"test\"], [train_size, val_size, test_size]):\n",
    "            tasks = [SineFunction(amplitude = random.uniform(self.amp_min, self.amp_max), \n",
    "                                     phase=random.uniform(self.phase_min, self.phase_max)) for _ in range(num_tasks)]\n",
    "            self.tasks[task_type] = tasks\n",
    "    \n",
    "    def get_batch_of_tasks(self, task_type, task_batch_size): \n",
    "        # helper function since same sampling per type for regression-specific domain\n",
    "        if task_batch_size is None: \n",
    "            # return all \n",
    "            return self.tasks[task_type]\n",
    "        else: \n",
    "            # sub-sample\n",
    "            # note: we could investigate impact of weighted sub-sampling in batch (?)\n",
    "            # see documentation: https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "            task_batch = np.random.choice(self.tasks[task_type], size=task_batch_size, replace=False)\n",
    "            return task_batch\n",
    "    \n",
    "    def get_meta_train_batch(self, task_batch_size=10): \n",
    "        return self.get_batch_of_tasks(\"train\", task_batch_size)\n",
    "        \n",
    "    def get_meta_val_batch(self, task_batch_size=None): \n",
    "        return self.get_batch_of_tasks(\"val\", task_batch_size) \n",
    "        \n",
    "    def get_meta_test_batch(self, task_batch_size=None): \n",
    "        return self.get_batch_of_tasks(\"test\", task_batch_size)\n",
    "\n",
    "        \n",
    "class SineFunction(): \n",
    "    \n",
    "    def __init__(self, amplitude, phase): \n",
    "        self.amplitude = amplitude\n",
    "        self.phase = phase\n",
    "        \n",
    "    def draw_sample(self, x): \n",
    "        '''\n",
    "        Sample from the specified sine wave \n",
    "        '''\n",
    "        # help to sample from a sine function:\n",
    "        # https://stackoverflow.com/questions/48043004/how-do-i-generate-a-sine-wave-using-python\n",
    "        freq = 1 # TODO: check???\n",
    "        return self.amplitude * np.sin(freq * x + self.phase)\n",
    "    \n",
    "    def get_samples(self, num_samples=10, \n",
    "                    min_query_x=-5.0, max_query_x=5.0): \n",
    "        '''\n",
    "        Return samples drawn from this specific function (e.g., K for training set in meta-train)\n",
    "        Note, input range uses values from paper (Section 5.1)\n",
    "        But modification allowed thru function so we can test generalization beyond??\n",
    "        '''\n",
    "        x_vals = [random.uniform(min_query_x, max_query_x) for _ in range(num_samples)]\n",
    "        y_vals = [self.draw_sample(x) for x in x_vals]\n",
    "        # TODO: check best form for later tensorflow modeling\n",
    "        return {\"input\": x_vals, \"output\": y_vals}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f192e0c",
   "metadata": {
    "id": "8f192e0c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sample of how to use the classes\n",
    "'''\n",
    "\n",
    "# using parameters from original MAML Section 5.1 (https://arxiv.org/pdf/1703.03400.pdf)\n",
    "amp_min=0.1\n",
    "amp_max=0.5\n",
    "phase_min=0\n",
    "phase_max=PI\n",
    "K = 10\n",
    "\n",
    "# todo: check parameters we want\n",
    "# specify the number of tasks to sample per meta-set\n",
    "meta_train_size=1000\n",
    "meta_val_size=100\n",
    "meta_test_size=1000\n",
    "meta_train_eval_size = 20\n",
    "\n",
    "task_batch_size = 10  \n",
    "\n",
    "dataset = RegressionDomain(amp_min=amp_min, amp_max=amp_max, \n",
    "                           phase_min=phase_min, phase_max=phase_max, \n",
    "                           train_size=meta_train_size, val_size=meta_val_size, test_size=meta_test_size)\n",
    "\n",
    "meta_val_set = dataset.get_meta_val_batch()\n",
    "meta_test_set = dataset.get_meta_test_batch()\n",
    "\n",
    "meta_train_sample = dataset.get_meta_train_batch(task_batch_size=task_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fd5b9",
   "metadata": {
    "id": "c82fd5b9",
    "outputId": "48ecf589-506c-44a2-ac27-12b2d6fa64ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': [1.1885017142054277,\n",
       "  3.760020375450811,\n",
       "  -0.5146124900538904,\n",
       "  -4.504138972840529,\n",
       "  2.145834185412564,\n",
       "  4.070895516452456,\n",
       "  1.6537979228382103,\n",
       "  4.508106696225958,\n",
       "  -3.28807849700528,\n",
       "  4.017073196731502],\n",
       " 'output': [0.19592657716818251,\n",
       "  -0.19061415261392065,\n",
       "  0.021301388246352065,\n",
       "  0.13625847993497528,\n",
       "  0.07390264278384374,\n",
       "  -0.20157328269437658,\n",
       "  0.1537550144088343,\n",
       "  -0.18440774898855625,\n",
       "  -0.09202404068985524,\n",
       "  -0.20105329686722476]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_sample[0].get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346a4725",
   "metadata": {
    "id": "346a4725"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=40, output_size=1):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        # Model layers\n",
    "        self.hidden1 = nn.Linear(input_size,hidden_size)\n",
    "        self.hidden2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "        #Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        y = x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qoxgJdXLC-jo",
   "metadata": {
    "id": "qoxgJdXLC-jo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "data_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
