{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Imports"
      ],
      "metadata": {
        "id": "UrjQGgr5nUHC"
      },
      "id": "UrjQGgr5nUHC"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Required imports for neural network\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import torchvision\n"
      ],
      "metadata": {
        "id": "eGl9mcc0nOMP"
      },
      "id": "eGl9mcc0nOMP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Data Loading and Generation"
      ],
      "metadata": {
        "id": "T3KVOwFXFOY0"
      },
      "id": "T3KVOwFXFOY0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Omniglot dataset\n",
        "\n",
        "Note this omniglot dataset has just 1000 images in the paper they report using 1200 for training"
      ],
      "metadata": {
        "id": "9nDo1jnW4wo4"
      },
      "id": "9nDo1jnW4wo4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import omniglot dataset\n",
        "dataset = torchvision.datasets.Omniglot(\n",
        "    root=\"./data\", download=True, transform=torchvision.transforms.ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqnEGwSRnOgX",
        "outputId": "35f504bc-fbfb-4694-dec8-ed04fac402c8"
      },
      "id": "AqnEGwSRnOgX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary for all classes there is 50\n",
        "dataset_classes={}\n",
        "for i in range(len(dataset)):\n",
        "  image, label = dataset[i]\n",
        "  try:\n",
        "    dataset_classes[f'{label}']= torch.cat((dataset_classes[f'{label}'],image[None,:,:,:]))\n",
        "  except:\n",
        "    dataset_classes[f'{label}']=image[None,:,:,:]\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "HEkrsJBool3Q"
      },
      "id": "HEkrsJBool3Q",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Omni:\n",
        "  x = []\n",
        "  y = []"
      ],
      "metadata": {
        "id": "bfYGR92aDqui"
      },
      "id": "bfYGR92aDqui",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number_of_classes = 964 #Define how money classes to train on, max is 50\n",
        "\n",
        "# # Create empty lists\n",
        "# dataset_list_train = []\n",
        "# dataset_list_train_label = []\n",
        "# dataset_list_test = []\n",
        "# dataset_list_test_label = []\n",
        "\n",
        "# # Extract traning data\n",
        "# for label in range(number_of_classes):\n",
        "#   for j in range(len(dataset_classes[f'{label}'])-1):\n",
        "#     dataset_list_train.append(dataset_classes[f'{label}'][j])\n",
        "#     dataset_list_train_label.append(label)\n",
        "\n",
        "# # Shuffle training data and labels\n",
        "# zip_train_for_shuffling = list(zip(dataset_list_train,dataset_list_train_label))\n",
        "# random.shuffle(zip_train_for_shuffling)\n",
        "# dataset_list_train,dataset_list_train_label = zip(*zip_train_for_shuffling)\n",
        "\n",
        "# # Extr<ct test data\n",
        "# for label in range(number_of_classes):\n",
        "#   dataset_list_test.append(dataset_classes[f'{label}'][-1])\n",
        "#   dataset_list_test_label.append(label)\n",
        "\n",
        "# # Shuffle test data and labels\n",
        "# zip_test_for_shuffling = list(zip(dataset_list_test,dataset_list_test_label))\n",
        "# random.shuffle(zip_test_for_shuffling)\n",
        "# dataset_list_test,dataset_list_test_label = zip(*zip_test_for_shuffling)\n",
        "\n",
        "# OMNI_TRAIN=[]\n",
        "# for _ in range(len(dataset_list_train_label)):\n",
        "#   OMNI_TRAIN.append(Omni())\n",
        "\n",
        "# OMNI_TEST=[]\n",
        "# for _ in range(len(dataset_list_test_label)):\n",
        "#   OMNI_TEST.append(Omni())\n",
        "\n",
        "# for i in range(len(dataset_list_train_label)):\n",
        "#   OMNI_TRAIN[i].x = dataset_list_train[i][None,:,:,:]\n",
        "#   OMNI_TRAIN[i].y = dataset_list_train_label[i]\n",
        "\n",
        "# for i in range(len(dataset_list_test_label)):\n",
        "#   OMNI_TEST[i].x = dataset_list_test[i][None,:,:,:]\n",
        "#   OMNI_TEST[i].y = dataset_list_test_label[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "vzxOBfUN3Q24"
      },
      "id": "vzxOBfUN3Q24",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Neural Network Model"
      ],
      "metadata": {
        "id": "cu4urLF7Q88A"
      },
      "id": "cu4urLF7Q88A"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define network\n",
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, output_size=964):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # network layers\n",
        "        self.hidden1 = nn.Conv2d(input_size,hidden_size,kernel_size=3)\n",
        "        self.hidden2 = nn.Conv2d(hidden_size,hidden_size,kernel_size=3)\n",
        "        self.hidden3 = nn.Conv2d(hidden_size,hidden_size,kernel_size=3)\n",
        "        self.hidden4 = nn.Conv2d(hidden_size,hidden_size,kernel_size=3)\n",
        "        self.batchnorm = nn.BatchNorm2d(hidden_size)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(1024,output_size)\n",
        "\n",
        "        #Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        # Convolutional part\n",
        "        x = self.hidden1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden3(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden4(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Fully-connected part\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "R1B0YTz6ytyN"
      },
      "id": "R1B0YTz6ytyN",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Helper functions"
      ],
      "metadata": {
        "id": "G-ExWACxQ3mt"
      },
      "id": "G-ExWACxQ3mt"
    },
    {
      "cell_type": "code",
      "source": [
        "# The Minimum Square Error is used to evaluate the difference between prediction and ground truth\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def transform_label(label,K=5):\n",
        "    label_tensor=torch.zeros((1,964))\n",
        "    label_tensor[:,label]=1\n",
        "\n",
        "    return label_tensor.repeat(K, 1).float()\n",
        "\n",
        "def copy_existing_model(model):\n",
        "    # Function to copy an existing model\n",
        "    # We initialize a new model\n",
        "    new_model = Neural_Network()\n",
        "    # Copy the previous model's parameters into the new model\n",
        "    new_model.load_state_dict(model.state_dict())\n",
        "    return new_model\n",
        "\n",
        "def initialization_to_store_meta_losses():\n",
        "  # This function creates lists to store the meta losses\n",
        "  global store_train_loss_meta; store_train_loss_meta = []\n",
        "  global store_test_loss_meta; store_test_loss_meta = []\n",
        "\n",
        "def test_set_validation(model,new_model,omni,lr_inner,k,store_test_loss_meta,K=1):\n",
        "    # This functions does not actually affect the main algorithm, it is just used to evaluate the new model\n",
        "    new_model = training(model, omni, lr_inner, k,K)\n",
        "    # Obtain the loss\n",
        "    loss = evaluation(new_model, omni,K)\n",
        "    # Store loss\n",
        "    store_test_loss_meta.append(loss)\n",
        "\n",
        "def train_set_evaluation(new_model,omni,store_train_loss_meta,K):\n",
        "    loss = evaluation(new_model, omni,K)\n",
        "    store_train_loss_meta.append(loss) \n",
        "\n",
        "def print_losses(epoch,store_train_loss_meta,store_test_loss_meta,printing_step=1000):\n",
        "  if epoch % printing_step == 0:\n",
        "    print(f'Epochh : {epoch}, Average Train Meta Loss : {np.mean(store_train_loss_meta)}, Average Test Meta Loss : {np.mean(store_test_loss_meta)}')\n",
        "\n",
        "#This is based on the paper update rule, we calculate the difference between parameters and then this is used by the optimizer, rather than doing the update by hand\n",
        "def reptile_parameter_update(model,new_model):\n",
        "  # Zip models for the loop\n",
        "  zip_models = zip(model.parameters(), new_model.parameters())\n",
        "  for parameter, new_parameter in zip_models:\n",
        "    if parameter.grad is None:\n",
        "      parameter.grad = torch.tensor(torch.zeros_like(parameter))\n",
        "    # Here we are adding the gradient that will later be used by the optimizer\n",
        "    parameter.grad.data.add_(parameter.data - new_parameter.data)\n",
        "\n",
        "# Define commands in order needed for the metaupdate\n",
        "# Note that if we change the order it doesn't behave the same\n",
        "def metaoptimizer_update(metaoptimizer):\n",
        "  # Take step\n",
        "  metaoptimizer.step()\n",
        "  # Reset gradients\n",
        "  metaoptimizer.zero_grad()\n",
        "\n",
        "def metaupdate(model,new_model,metaoptimizer):\n",
        "  # Combine the two previous functions into a single metaupdate function\n",
        "  # First we calculate the gradients\n",
        "  reptile_parameter_update(model,new_model)\n",
        "  # Use those gradients in the optimizer\n",
        "  metaoptimizer_update(metaoptimizer)\n",
        "\n",
        "def evaluation(new_model, omni, K, item = True):\n",
        "    # Get data\n",
        "    x, label = omni.x,omni.y\n",
        "    # Make model prediction\n",
        "    prediction = new_model(x)\n",
        "    # Get loss\n",
        "    if item == True: #Depending on whether we need to return the loss value for storing or for backprop\n",
        "      loss = criterion(prediction,transform_label(label,K=K)).item()\n",
        "    else:\n",
        "      loss = criterion(prediction,transform_label(label,K=K))\n",
        "    return loss\n",
        "\n",
        "def training(model, omni, lr_k, k, K):\n",
        "    # Create new model which we will train on\n",
        "    new_model = copy_existing_model(model)\n",
        "    # Define new optimizer\n",
        "    koptimizer = torch.optim.SGD(new_model.parameters(), lr=lr_k)\n",
        "    # Update the model multiple times, note that k>1 (do not confuse k with K)\n",
        "    for i in range(k):\n",
        "        # Reset optimizer\n",
        "        koptimizer.zero_grad()\n",
        "        # Evaluate the model\n",
        "        loss = evaluation(new_model, omni, K, item = False)\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        koptimizer.step()\n",
        "    return new_model"
      ],
      "metadata": {
        "id": "1zyNHFXdOnug"
      },
      "id": "1zyNHFXdOnug",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Reptile"
      ],
      "metadata": {
        "id": "-4Ps8P2IRCmF"
      },
      "id": "-4Ps8P2IRCmF"
    },
    {
      "cell_type": "code",
      "source": [
        "#Define important variables\n",
        "epochs = int(1e4) # number of epochs \n",
        "lr_meta=0.001 # Learning rate for meta model (outer loop)\n",
        "printing_step=100 # how many epochs should we wait to print the loss\n",
        "lr_k=0.0005 # Internal learning rate\n",
        "k=5 # Number of internal updates for each task\n",
        "\n",
        "# Training loop\n",
        "K = 5 #Max is 20\n",
        "number_of_tasks = 963 #Max 964\n",
        "\n",
        "# Initializations\n",
        "initialization_to_store_meta_losses()\n",
        "model = Neural_Network()\n",
        "metaoptimizer = torch.optim.Adam(model.parameters(), lr=lr_meta,betas=(0, 0.999))"
      ],
      "metadata": {
        "id": "8ogpg_DHizlC"
      },
      "id": "8ogpg_DHizlC",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "        \n",
        "    # Sample a sine omni (Task from training data)\n",
        "    label = random.randint(0,number_of_tasks-1)\n",
        "    sampling = random.randint(0,15)\n",
        "    #need a random shuffle function\n",
        "    data = dataset_classes[f'{label}'][sampling:sampling+5,:,:,:]\n",
        "    omni = Omni()\n",
        "    omni.x = data\n",
        "    omni.y = label\n",
        "\n",
        "    # Update model predefined number of times based on k\n",
        "    new_model = training(model, omni, lr_k, k,K=K)\n",
        "\n",
        "    # Evalaute the loss for the training data\n",
        "    train_set_evaluation(new_model,omni,store_train_loss_meta,K=K)     \n",
        "    \n",
        "    #Meta-update --> Get gradient for meta loop and update\n",
        "    metaupdate(model,new_model,metaoptimizer)\n",
        "    \n",
        "    # Evalaute the loss for the test data\n",
        "    # Note that we need to sample the omni from the test data\n",
        "    # Sample a sine omni (Task from training data)\n",
        "    label = 963\n",
        "    data = dataset_classes[f'{label}'][sampling:sampling+5,:,:,:]\n",
        "      \n",
        "    omni = Omni()\n",
        "    omni.x = data\n",
        "    omni.y = label\n",
        "\n",
        "\n",
        "    test_set_validation(model,new_model,omni,lr_k,k,store_test_loss_meta,K=K)\n",
        "\n",
        "    # Print losses every 'printing_step' epochs\n",
        "    print_losses(epoch,store_train_loss_meta,store_test_loss_meta,printing_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "-4-zQWWKFt3s",
        "outputId": "b8a68158-2bb7-4565-86cc-ae188d2dda13"
      },
      "id": "-4-zQWWKFt3s",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochh : 0, Average Train Meta Loss : 0.007717070169746876, Average Test Meta Loss : 0.008455774746835232\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1c04f4cb2a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Update model predefined number of times based on k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Evalaute the loss for the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fa1acda1cde4>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, omni, lr_k, k, K)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mkoptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'reptile_classification')"
      ],
      "metadata": {
        "id": "4455Z3LWx9jG"
      },
      "id": "4455Z3LWx9jG",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('reptile_classification')"
      ],
      "metadata": {
        "id": "NZmTOUuKyG25"
      },
      "id": "NZmTOUuKyG25",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Few Shot learning with new meta-model"
      ],
      "metadata": {
        "id": "bQjoz6FYctJM"
      },
      "id": "bQjoz6FYctJM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs good few shot learning"
      ],
      "metadata": {
        "id": "m-SPUG5Bfpe9"
      },
      "id": "m-SPUG5Bfpe9"
    },
    {
      "cell_type": "code",
      "source": [
        "label = 963\n",
        "data = dataset_classes[f'{label}'][0:K,:,:,:]\n",
        "      \n",
        "omni = Omni()\n",
        "omni.x = data\n",
        "omni.y = label\n",
        "k_shot_updates = 5\n",
        "initialization_to_store_meta_losses()\n",
        "for shots in range(k_shot_updates):\n",
        "    new_model = training(model, omni, lr_k, shots,K)\n",
        "    train_set_evaluation(new_model,omni,store_train_loss_meta,K) \n",
        "\n",
        "plt.plot(store_train_loss_meta,label = 'Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('k shots')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GY84TNs8JXVH",
        "outputId": "c174c2d4-b83a-47c8-dadd-10a77b600447"
      },
      "id": "GY84TNs8JXVH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'k shots')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3HnhyvJRa_H",
        "outputId": "0bbec6f0-cdcb-473c-dcd3-6e6e9cf93e27"
      },
      "id": "B3HnhyvJRa_H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1-7gq-dsIM21"
      },
      "id": "1-7gq-dsIM21",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Reptile_classification_omniglot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}